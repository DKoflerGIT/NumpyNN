{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building custom Neural Networks in Compyute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compyute as cp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from compyute.preprocessing import split_train_val_test, normalize\n",
    "\n",
    "# download the data\n",
    "url = \"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# encode the targets\n",
    "data[\"variety\"] = data[\"variety\"].astype(\"category\").cat.codes\n",
    "data_tensor = cp.tensor(data.to_numpy())\n",
    "\n",
    "# split the data into train, val, test\n",
    "train, val, test = split_train_val_test(data_tensor, ratio_val=0.25, ratio_test=0.25)\n",
    "\n",
    "# split features from targets\n",
    "X_train, y_train = train[:, :-1], train[:, -1].to_int()\n",
    "X_val, y_val = val[:, :-1], val[:, -1].to_int()\n",
    "X_test, y_test = test[:, :-1], test[:, -1].to_int()\n",
    "\n",
    "# normalize features\n",
    "X_train = normalize(X_train, dim=0, low=-1, high=1)\n",
    "X_val = normalize(X_val, dim=0, low=-1, high=1)\n",
    "X_test = normalize(X_test, dim=0, low=-1, high=1)\n",
    "\n",
    "print (f'{X_train.shape=}')\n",
    "print (f'{y_train.shape=}')\n",
    "print (f'{X_val.shape=}')\n",
    "print (f'{y_val.shape=}')\n",
    "print (f'{X_test.shape=}')\n",
    "print (f'{y_test.shape=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Custom Model Architecture\n",
    "If you want to define very specifically what the forward and backward pass of your model should look like, you can build your own custom model instead of using the predefined sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compyute import nn\n",
    "\n",
    "class MyCustomModel(nn.Module):  # inherit from nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # define your layers\n",
    "        self.lin1 = nn.Linear(4, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(16, 3)\n",
    "\n",
    "    # define the forward pass\n",
    "    @nn.Module.register_forward\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "    # define the backward pass\n",
    "    @nn.Module.register_backward\n",
    "    def backward(self, dy):\n",
    "        dy = self.lin2.backward(dy)\n",
    "        dy = self.relu.backward(dy)\n",
    "        dy = self.lin1.backward(dy)\n",
    "        return dy\n",
    "        \n",
    "\n",
    "model = MyCustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = cp.nn.utils.get_module_summary(model, input_shape=(4,))\n",
    "print(summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a custom Training Loop\n",
    "\n",
    "You can also write a custom training loop instead of using the `Trainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "batch_size = X_train.shape[0]\n",
    "\n",
    "train_dl = nn.utils.Dataloader((X_train, y_train), batch_size=batch_size)\n",
    "val_dl = nn.utils.Dataloader((X_val, y_val), batch_size=batch_size)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = nn.optimizers.SGD(model.get_parameters(), lr=1e-2)\n",
    "\n",
    "for e in range(epochs):\n",
    "    # training\n",
    "    model.training()\n",
    "    for x, y in train_dl():\n",
    "        # forward pass\n",
    "        y_pred = model(x)\n",
    "        _ = loss_fn(y_pred, y)\n",
    "\n",
    "        # backward pass\n",
    "        model.backward(loss_fn.backward())  # compute new gradients\n",
    "        optim.step()  # update parameters\n",
    "        optim.reset_grads()  # reset all gradients\n",
    "    \n",
    "    # validiation\n",
    "    model.inference()\n",
    "    with nn.no_cache_ctx():  # disable caching of contextual data for gradient computation\n",
    "        val_loss = 0\n",
    "        for x, y in val_dl():\n",
    "            y_pred = model(x)\n",
    "            val_loss += loss_fn(y_pred, y).item()\n",
    "        val_loss /= len(val_dl)\n",
    "        print(f\"epoch {e}: {val_loss=:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "deee277ef8cb4a05cf6441d551c854fa5e547ddedbca2c10e6f5685ea62b6c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
