{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # for sibling import\n",
    "\n",
    "import compyute as cp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3.2\n",
    "\n",
    "### Deep neural network using a custom model\n",
    "\n",
    "The goal of this model is to classify iris species based on numerical features.\n",
    "\n",
    "### Step 1: Prepare data\n",
    "You will need to download the dataset from https://www.kaggle.com/datasets/uciml/iris and place it into the *data* directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from compyute.preprocessing import normalize, split_train_val_test\n",
    "\n",
    "\n",
    "data_orig = pd.read_csv('../data/iris.csv')\n",
    "data = data_orig.copy()\n",
    "data.drop(columns=['Id'], inplace=True)\n",
    "\n",
    "data[\"Species\"] = data[\"Species\"].astype(\"category\").cat.codes\n",
    "\n",
    "data_tensor = cp.tensor(data.to_numpy())\n",
    "train, val, test = split_train_val_test(data_tensor)\n",
    "\n",
    "X_train, y_train = train[:, :-1], train[:, -1].int()\n",
    "X_val, y_val = val[:, :-1], val[:, -1].int()\n",
    "X_test, y_test = test[:, :-1], test[:, -1].int()\n",
    "\n",
    "X_train = normalize(X_train, axis=0)\n",
    "X_val = normalize(X_val, axis=0)\n",
    "X_test = normalize(X_test, axis=0)\n",
    "\n",
    "print (f'{X_train.shape=}')\n",
    "print (f'{y_train.shape=}')\n",
    "\n",
    "print (f'{X_val.shape=}')\n",
    "print (f'{y_val.shape=}')\n",
    "\n",
    "print (f'{X_test.shape=}')\n",
    "print (f'{y_test.shape=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build a custom model\n",
    "If you want to define very specifically what the forward and backward pass of your model should look like, you can build your own custom model instead of using the predefined sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compyute.nn as nn\n",
    "\n",
    "class MyCustomModel(nn.Container):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # define your layers\n",
    "        self.lin1 = nn.Linear(4, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.Batchnorm1d(16)\n",
    "        self.lin2 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define the forward pass\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        # define the backward pass\n",
    "        def backward(dy):\n",
    "            dy = self.lin2.backward(dy)\n",
    "            dy = self.bn.backward(dy)\n",
    "            dy = self.relu.backward(dy)\n",
    "            dy = self.lin1.backward(dy)\n",
    "            return dy\n",
    "        self.backward_fn = backward\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = MyCustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(input_shape=(4,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compyute.nn.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=\"sgd\",\n",
    "    loss=\"cross_entropy\",\n",
    "    metric=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(X_train, y_train, epochs=300, val_data=(X_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate the model\n",
    "Using the defined metric, the model's performance can be evaluated using testing/validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = trainer.evaluate_model(X_test, y_test)\n",
    "print(f'loss {loss:.4f}')\n",
    "print(f'accuracy {100*accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "deee277ef8cb4a05cf6441d551c854fa5e547ddedbca2c10e6f5685ea62b6c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
