{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compyute as cp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3.2\n",
    "\n",
    "### Deep neural network using a custom model\n",
    "\n",
    "The goal of this model is to classify iris species based on numerical features, but this time the model and the training loop are written \"from scratch\".\n",
    "\n",
    "### Step 1: Prepare data\n",
    "You will need to download the dataset from https://www.kaggle.com/datasets/uciml/iris and place it into the *data* directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from compyute.preprocessing import normalize, split_train_val_test\n",
    "\n",
    "\n",
    "data_orig = pd.read_csv('../data/iris.csv')\n",
    "data = data_orig.copy()\n",
    "data.drop(columns=['Id'], inplace=True)\n",
    "\n",
    "data[\"Species\"] = data[\"Species\"].astype(\"category\").cat.codes\n",
    "\n",
    "data_tensor = cp.tensor(data.to_numpy())\n",
    "train, val, test = split_train_val_test(data_tensor, ratio_val=0.25, ratio_test=0.25)\n",
    "\n",
    "X_train, y_train = train[:, :-1], train[:, -1].int()\n",
    "X_val, y_val = val[:, :-1], val[:, -1].int()\n",
    "X_test, y_test = test[:, :-1], test[:, -1].int()\n",
    "\n",
    "X_train = normalize(X_train, axis=0)\n",
    "X_val = normalize(X_val, axis=0)\n",
    "X_test = normalize(X_test, axis=0)\n",
    "\n",
    "print (f'{X_train.shape=}')\n",
    "print (f'{y_train.shape=}')\n",
    "\n",
    "print (f'{X_val.shape=}')\n",
    "print (f'{y_val.shape=}')\n",
    "\n",
    "print (f'{X_test.shape=}')\n",
    "print (f'{y_test.shape=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build a custom model\n",
    "If you want to define very specifically what the forward and backward pass of your model should look like, you can build your own custom model instead of using the predefined sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compyute.nn as nn\n",
    "\n",
    "class MyCustomModel(nn.Container):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # define your layers\n",
    "        self.lin1 = nn.Linear(4, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define the forward pass\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        # define the backward pass\n",
    "        if self.training:\n",
    "            def backward(dy):\n",
    "                dy = self.lin2.backward(dy)\n",
    "                dy = self.relu.backward(dy)\n",
    "                dy = self.lin1.backward(dy)\n",
    "                return dy\n",
    "            self._backward = backward\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = MyCustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(input_shape=(4,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train the model\n",
    "\n",
    "You can also write a custom training loop instead of using the `Trainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "batch_size = X_train.shape[0]\n",
    "\n",
    "train_dl = nn.DataLoader(X_train, y_train, batch_size)\n",
    "val_dl = nn.DataLoader(X_val, y_val, batch_size)\n",
    "loss_func = nn.CrossEntropy()\n",
    "optim = nn.optimizers.SGD(model.parameters)\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    # training\n",
    "    model.set_training(True)\n",
    "    for x, y in train_dl():\n",
    "        # forward pass\n",
    "        y_pred = model(x)\n",
    "        _ = loss_func(y_pred, y)\n",
    "\n",
    "        # backward pass\n",
    "        optim.reset_grads()  # reset all gradients\n",
    "        model.backward(loss_func.backward())  # compute new gradients\n",
    "        optim.step()  # update parameters\n",
    "    \n",
    "    # validiation\n",
    "    model.set_training(False)\n",
    "    val_loss = 0\n",
    "    for x, y in val_dl():\n",
    "        y_pred = model(x)\n",
    "        val_loss += loss_func(y_pred, y).item()\n",
    "    val_loss /= len(val_dl)\n",
    "    print(f\"epoch {e}: {val_loss=:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "deee277ef8cb4a05cf6441d551c854fa5e547ddedbca2c10e6f5685ea62b6c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
