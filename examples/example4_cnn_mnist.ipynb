{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # for sibling import\n",
    "\n",
    "import random\n",
    "import compyute as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if cp.engine.gpu_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4\n",
    "\n",
    "### Convolutional Neural Network: MNIST\n",
    "\n",
    "The goal of this model is to classify images of hand-written digits.\n",
    "\n",
    "### Step 1: Prepare data\n",
    "You will need to download the dataset from https://www.kaggle.com/competitions/digit-recognizer/data and place it into the *data* directory. Only using the official training data for training, validation and testing, since it is just to showcase the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/mnist/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = cp.Tensor(data.to_numpy())\n",
    "train, val, test = cp.preprocessing.split_train_val_test(tensor, ratio_val=0.1, ratio_test=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train[:, 1:], train[:, 0].int()\n",
    "X_val, y_val = val[:, 1:], val[:, 0].int()\n",
    "X_test, y_test = test[:, 1:], test[:, 0].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 1 , 28, -1)).float()\n",
    "X_val = X_val.reshape((X_val.shape[0], 1, 28, -1)).float()\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, 28, -1)).float()\n",
    "\n",
    "print (f'{X_train.shape=}')\n",
    "print (f'{y_train.shape=}')\n",
    "\n",
    "print (f'{X_val.shape=}')\n",
    "print (f'{y_val.shape=}')\n",
    "\n",
    "print (f'{X_test.shape=}')\n",
    "print (f'{y_test.shape=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build the neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compyute.nn as nn\n",
    "\n",
    "model = nn.SequentialModel([\n",
    "    nn.Convolution2dBlock(1, 32, kernel_size=3, activation=\"relu\"),\n",
    "    nn.MaxPooling2d(kernel_size=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(13*13*32, 10)\n",
    "])\n",
    "model.to_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(input_shape=(1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train the model\n",
    "\n",
    "To avoid overfitting the model, the `EarlyStopping`-Callback can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compyute.nn.trainer import callbacks, losses, metrics, optimizers, Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizers.Adam(),\n",
    "    loss=losses.Crossentropy(),\n",
    "    metric=metrics.Accuracy(),\n",
    "    callbacks=[callbacks.EarlyStopping(target=\"val_loss\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "model.retain_values = True\n",
    "trainer.train(X_train, y_train, epochs=epochs, batch_size=batch_size, val_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(t1, t2):\n",
    "    trace1 = trainer.state[t1]\n",
    "    trace2 = trainer.state[t2]\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(cp.arange(start=1, stop=len(trace1) + 1).to_numpy(), trace1, linewidth=1)\n",
    "    plt.plot(cp.arange(start=1, stop=len(trace2) + 1).to_numpy(), trace2, linewidth=1)\n",
    "    plt.legend([t1, t2])\n",
    "    plt.grid(color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "plot_history(\"epoch_loss\", \"epoch_val_loss\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = trainer.evaluate_model(X_test, y_test, batch_size)\n",
    "print(f'loss {loss:.4f}')\n",
    "print(f'accuracy {accuracy*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "cm = confusion_matrix(y_test.to_numpy(), nn.functional.softmax(y_pred).argmax(-1).to_numpy(), labels=y_test.unique().to_numpy())\n",
    "\n",
    "r = cp.arange(10).to_numpy()\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.xticks(ticks=r, labels=r)\n",
    "plt.yticks(ticks=r, labels=r)\n",
    "for (j, i), label in numpy.ndenumerate(cm):\n",
    "    plt.text(i, j, str(int(label)), ha=\"center\", va=\"center\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Explore the inner workings\n",
    "Pick a random image from the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(X_test) - 1)\n",
    "image = X_test[i].moveaxis(0, -1)  # matplotlib needs the color channel to be the last dim\n",
    "plt.figure(figsize=(3, 3))\n",
    "plot = plt.imshow(image.data, cmap='gray')\n",
    "plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use it to predict a number and show the probability distribution of the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = X_test[None, i]\n",
    "print(f\"correct label: {y_test[i].item()}\")\n",
    "\n",
    "image_tensor.to_device(device)\n",
    "logits = model(image_tensor)\n",
    "probs = cp.nn.functional.softmax(logits.cpu())\n",
    "preds = probs.argmax(-1)\n",
    "\n",
    "print(f\"predicted label: {preds.item()}\")\n",
    "\n",
    "preds = logits.argmax(-1)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.xticks(ticks=r)\n",
    "plt.bar(r, probs.reshape((10,)).data)\n",
    "plt.xlabel(\"class\")\n",
    "plt.ylabel(\"probability\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every layer of the model can be accessed to explore their output. Here we iterate over all the kernels of the convolutional layer to explore what they learned to focus on in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = model.module.modules[0].modules[0]\n",
    "\n",
    "def plot_channels(array, label):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(array.shape[0]):\n",
    "        plt.subplot(10, 8, i + 1)\n",
    "        image = array[i, :, :]\n",
    "        plt.imshow(image, vmin=image.min().item(), vmax=image.max().item(), cmap=\"gray\")\n",
    "        plt.xlabel(f\"channel {str(i + 1)}\")\n",
    "        plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_y = (conv.y[0] - conv.b.reshape((conv.y.shape[1], 1, 1))).cpu()\n",
    "plot_channels(conv_y, \"channel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learned filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_w = conv.w.squeeze().cpu()\n",
    "plot_channels(conv_w.data, \"filter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which areas does each filter focus on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.retain_values = False\n",
    "x_ones = cp.ones((1, *X_test.shape[1:]))\n",
    "x_ones.to_device(device)\n",
    "y_ones = conv(x_ones)\n",
    "y_ones = (y_ones - conv.b.reshape((y_ones.shape[1], 1, 1))).squeeze().cpu()\n",
    "conv.retain_values = True\n",
    "\n",
    "plot_channels(y_ones, \"filter\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "deee277ef8cb4a05cf6441d551c854fa5e547ddedbca2c10e6f5685ea62b6c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
