{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import compyute as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if cp.engine.gpu_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4\n",
    "\n",
    "### Convolutional Neural Network: LeNet & MNIST\n",
    "\n",
    "The goal of this model is to classify images of hand-written digits.\n",
    "\n",
    "### Step 1: Prepare data\n",
    "You will need to download the dataset from https://www.kaggle.com/competitions/digit-recognizer/data and place it into the *data* directory. Only using the official training data for training, validation and testing, since it is just to showcase the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/mnist/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = cp.tensor(data.to_numpy())\n",
    "train, val, test = cp.preprocessing.split_train_val_test(tensor, ratio_val=0.1, ratio_test=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train[:, 1:], train[:, 0].to_int()\n",
    "X_val, y_val = val[:, 1:], val[:, 0].to_int()\n",
    "X_test, y_test = test[:, 1:], test[:, 0].to_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cp.reshape(X_train, shape=(X_train.shape[0], 1 , 28, -1)).to_float()\n",
    "X_val = cp.reshape(X_val, shape=(X_val.shape[0], 1, 28, -1)).to_float()\n",
    "X_test = cp.reshape(X_test, shape=(X_test.shape[0], 1, 28, -1)).to_float()\n",
    "\n",
    "print(f'{X_train.shape=}')\n",
    "print(f'{y_train.shape=}')\n",
    "print(f'{X_val.shape=}')\n",
    "print(f'{y_val.shape=}')\n",
    "print(f'{X_test.shape=}')\n",
    "print(f'{y_test.shape=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build the neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compyute.nn as nn\n",
    "\n",
    "# LeNet\n",
    "model = nn.Sequential(\n",
    "    nn.Convolution2DBlock(1, 6, kernel_size=5, activation=\"sigmoid\", padding=\"same\"),\n",
    "    nn.AvgPooling2D(kernel_size=2),\n",
    "\n",
    "    nn.Convolution2DBlock(6, 16, kernel_size=5, activation=\"sigmoid\", padding=\"valid\"),\n",
    "    nn.AvgPooling2D(kernel_size=2),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.DenseBlock(16*5*5, 120, activation=\"sigmoid\"),\n",
    "    nn.DenseBlock(120, 84, activation=\"sigmoid\"),\n",
    "    nn.Linear(84, 10)\n",
    ")\n",
    "\n",
    "model.to_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = model.get_summary(input_shape=(1, 28, 28))\n",
    "print(summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compyute.nn.trainer import Trainer\n",
    "from compyute.nn.trainer.callbacks import History, ProgressBar\n",
    "\n",
    "history = History()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=nn.optimizers.Adam(),\n",
    "    loss=nn.CrossEntropy(),\n",
    "    metric=nn.Accuracy(),\n",
    "    callbacks=[\n",
    "        history,\n",
    "        ProgressBar(mode=\"step\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "trainer.train(X_train, y_train, epochs=epochs, batch_size=batch_size, val_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(t1, t2):\n",
    "    trace1 = history[t1]\n",
    "    trace2 = history[t2]\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(cp.arange(start=1, stop=len(trace1) + 1), trace1, linewidth=1)\n",
    "    plt.plot(cp.arange(start=1, stop=len(trace2) + 1), trace2, linewidth=1)\n",
    "\n",
    "plot_history(\"loss\", \"accuracy_score\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = trainer.evaluate_model(X_test, y_test, batch_size)\n",
    "print(f'loss {loss:.4f}')\n",
    "print(f'accuracy {accuracy*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy\n",
    "from compyute.nn.utils import batched\n",
    "\n",
    "y_pred = batched(model, batch_size=batch_size, device=model.device, shuffle_data=False)(X_test)\n",
    "probs, _ = nn.functional.softmax(y_pred)\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    y_true=y_test.to_numpy(),\n",
    "    y_pred=cp.argmax(probs, axis=-1).to_numpy(),\n",
    "    labels=cp.unique(y_test).to_numpy()\n",
    ")\n",
    "\n",
    "r = cp.arange(10).to_numpy()\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.xticks(ticks=r, labels=r)\n",
    "plt.yticks(ticks=r, labels=r)\n",
    "for (j, i), label in numpy.ndenumerate(cm):\n",
    "    plt.text(i, j, str(int(label)), ha=\"center\", va=\"center\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Explore the inner workings\n",
    "Pick a random image from the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(X_test) - 1)\n",
    "image = cp.moveaxis(X_test[i], from_axis=0, to_axis=-1)  # matplotlib needs the color channel to be the last dim\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(image.data, cmap='gray')\n",
    "plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use it to predict a number and show the probability distribution of the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"correct label: {y_test[i].item()}\")\n",
    "\n",
    "image_tensor = X_test[None, i].to_device(device)\n",
    "\n",
    "# retain values so we can look at intermediates\n",
    "with model.do_retain_values():\n",
    "    logits = model(image_tensor)\n",
    "\n",
    "probs = cp.squeeze(cp.nn.functional.softmax(logits)[0])\n",
    "pred = cp.squeeze(cp.argmax(probs, axis=-1)).item()\n",
    "\n",
    "print(f\"predicted label: {pred}\")\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.xticks(ticks=r)\n",
    "plt.bar(r, probs.to_numpy())\n",
    "plt.xlabel(\"class\")\n",
    "plt.ylabel(\"probability\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every layer of the model can be accessed to explore their output. Here we iterate over all the kernels of the convolutional layer to explore what they learned to focus on in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_channels(array, label):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(array.shape[0]):\n",
    "        plt.subplot(10, 8, i + 1)\n",
    "        image = array[i, :, :]\n",
    "        plt.imshow(image, vmin=cp.min(image).item(), vmax=cp.max(image).item(), cmap=\"gray\")\n",
    "        plt.xlabel(f\"channel {str(i + 1)}\")\n",
    "        plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = model.modules[0].modules[0]\n",
    "\n",
    "out = conv1.y[0].to_cpu()\n",
    "out_min = cp.min(out, axis=0)\n",
    "out_max = cp.max(out, axis=0)\n",
    "out = (out - out_min) / (out_max - out_min)\n",
    "plot_channels(out, \"channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = model.modules[2].modules[0]\n",
    "\n",
    "out2 = conv2.y[0].to_cpu()\n",
    "out_min2 = cp.min(out2, axis=0)\n",
    "out_max2 = cp.max(out2, axis=0)\n",
    "out2 = (out2 - out_min2) / (out_max2 - out_min2)\n",
    "plot_channels(out2, \"channel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learned filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = cp.sum(conv1.w, axis=1).to_cpu()\n",
    "weights_min1 = cp.min(weights1, axis=0)\n",
    "weights_max1 = cp.max(weights1, axis=0)\n",
    "weights1 = (weights1 - weights_min1) / (weights_max1 - weights_min1)\n",
    "plot_channels(weights1, \"filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2 = cp.sum(conv2.w, axis=1).to_cpu()\n",
    "weights_min2 = cp.min(weights2, axis=0)\n",
    "weights_max2 = cp.max(weights2, axis=0)\n",
    "weights2 = (weights2 - weights_min2) / (weights_max2 - weights_min2)\n",
    "plot_channels(weights2, \"filter\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "deee277ef8cb4a05cf6441d551c854fa5e547ddedbca2c10e6f5685ea62b6c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
