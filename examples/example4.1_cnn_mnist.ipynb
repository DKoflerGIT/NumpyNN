{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # for sibling import\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import walnut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if walnut.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4.1\n",
    "\n",
    "### Convolutional Neural Network: MNIST\n",
    "\n",
    "The goal of this model is to classify images of hand-written digits.\n",
    "\n",
    "### Step 1: Prepare data\n",
    "You will need to download the dataset from https://www.kaggle.com/competitions/digit-recognizer/data and place it into the *data* directory. Only using the official training data for training, validation and testing, since it is just to showcase the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/mnist/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = walnut.df_to_tensor(data)\n",
    "train, val, test = walnut.preprocessing.split_train_val_test(tensor, ratio_val=0.1, ratio_test=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train[:, 1:], train[:, 0].astype(\"int32\")\n",
    "X_val, y_val = val[:, 1:], val[:, 0].astype(\"int32\")\n",
    "X_test, y_test = test[:, 1:], test[:, 0].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 1 , 28, -1))\n",
    "X_val = X_val.reshape((X_val.shape[0], 1, 28, -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, 28, -1))\n",
    "\n",
    "print (f'{X_train.shape=}')\n",
    "print (f'{y_train.shape=}')\n",
    "\n",
    "print (f'{X_val.shape=}')\n",
    "print (f'{y_val.shape=}')\n",
    "\n",
    "print (f'{X_test.shape=}')\n",
    "print (f'{y_test.shape=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build the neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import walnut.nn as nn\n",
    "from walnut.nn.layers import *\n",
    "\n",
    "model = nn.Sequential([\n",
    "    Convolution2d(1, 32, kernel_size=(3, 3)),\n",
    "    ReLU(),\n",
    "    MaxPooling2d(kernel_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Linear(13*13*32, 256),\n",
    "    ReLU(),\n",
    "    Linear(256, 10)\n",
    "])\n",
    "\n",
    "model.to_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=nn.optimizers.Adam(),\n",
    "    loss_fn=nn.losses.Crossentropy(),\n",
    "    metric_fn=nn.metrics.get_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from walnut.nn.analysis import model_summary\n",
    "model_summary(model, (1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 350\n",
    "\n",
    "train_losses, train_scores, _, _ = model.train(X_train, y_train, epochs=epochs, batch_size=batch_size, val_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = {\n",
    "    \"train_loss\" : train_losses,\n",
    "    \"train_accuracy\" : train_scores\n",
    "}\n",
    "\n",
    "nn.analysis.plot_curve(traces=traces, figsize=(15, 3), title=\"train history\", x_label=\"steps\", y_label=\"loss/accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, batch_size)\n",
    "print(f'loss {loss:.4f}')\n",
    "print(f'accuracy {accuracy*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test, batch_size=batch_size)\n",
    "nn.analysis.plot_confusion_matrix(predictions, y_test, figsize=(5,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Explore the inner workings\n",
    "Pick a random image from the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, X_test.len - 1)\n",
    "image = X_test[i].moveaxis(0, -1)  # matplotlib needs the color channel to be the last dim\n",
    "plt.figure(figsize=(3, 3))\n",
    "plot = plt.imshow(image.data, cmap='gray')\n",
    "plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use it to predict a number and show the probability distribution of the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = walnut.expand_dims(X_test[i], 0)\n",
    "print(f\"correct label: {y_test[i].item()}\")\n",
    "\n",
    "image_tensor.to_device(device)\n",
    "logits = model(image_tensor).cpu()\n",
    "\n",
    "print(f\"predicted label: {logits.argmax(-1).item()}\")\n",
    "nn.analysis.plot_probabilities(logits, figsize=(6, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every layer of the model can be accessed to explore their output. Here we iterate over all the kernels of the convolutional layer to explore what they learned to focus on in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = {f\"{i + 1} {l.__class__.__name__}\" : l.y.cpu().data[0] for i, l in enumerate(model.sub_modules[0].sub_modules) if l.__class__.__name__ == \"Convolution2d\"}\n",
    "nn.analysis.plot_images(channels, figsize=(40, 40), cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "deee277ef8cb4a05cf6441d551c854fa5e547ddedbca2c10e6f5685ea62b6c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
