{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network: MNIST\n",
    "\n",
    "based on https://towardsdatascience.com/going-beyond-99-mnist-handwritten-digits-recognition-cfff96337392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import compyute as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cp.cuda if cp.backend.gpu_available() else cp.cpu\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# download the datasets\n",
    "train_url = \"https://pjreddie.com/media/files/mnist_train.csv\"\n",
    "train_data = pd.read_csv(train_url)\n",
    "train_tensor = cp.tensor(train_data.to_numpy())\n",
    "\n",
    "test_url = \"https://pjreddie.com/media/files/mnist_test.csv\"\n",
    "test_data = pd.read_csv(test_url)\n",
    "test = cp.tensor(test_data.to_numpy())\n",
    "\n",
    "# split the data into train, val, test\n",
    "train, val, _ = cp.preprocessing.split_train_val_test(train_tensor, ratio_val=0.2, ratio_test=0.0)\n",
    "\n",
    "# split features from targets\n",
    "X_train, y_train = train[:, 1:], train[:, 0].to_int()\n",
    "X_val, y_val = val[:, 1:], val[:, 0].to_int()\n",
    "X_test, y_test = test[:, 1:], test[:, 0].to_int()\n",
    "\n",
    "# reshape the data into an image format (B, 784) -> (B, 1, 28, 28)\n",
    "X_train = cp.reshape(X_train, shape=(X_train.shape[0], 1 , 28, -1)).to_float()\n",
    "X_val = cp.reshape(X_val, shape=(X_val.shape[0], 1, 28, -1)).to_float()\n",
    "X_test = cp.reshape(X_test, shape=(X_test.shape[0], 1, 28, -1)).to_float()\n",
    "\n",
    "# scaling\n",
    "def scale(x: cp.Tensor) -> cp.Tensor:\n",
    "    mean_px = x.mean().to_type(cp.float32)\n",
    "    std_px = x.std().to_type(cp.float32)\n",
    "    return (x - mean_px)/(std_px)\n",
    "\n",
    "X_train = scale(X_train)\n",
    "X_val = scale(X_val)\n",
    "X_test = scale(X_test)\n",
    "\n",
    "print(f'{X_train.shape=}')\n",
    "print(f'{y_train.shape=}')\n",
    "print(f'{X_val.shape=}')\n",
    "print(f'{y_val.shape=}')\n",
    "print(f'{X_test.shape=}')\n",
    "print(f'{y_test.shape=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compyute import nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2D(1, 32, 5), nn.ReLU(),\n",
    "    nn.Conv2D(32, 32, 5, bias=False), nn.BatchNorm2D(32), nn.ReLU(),\n",
    "    nn.MaxPooling2D(2), nn.Dropout(0.25),\n",
    "    \n",
    "    nn.Conv2D(32, 64, 3), nn.ReLU(),\n",
    "    nn.Conv2D(64, 64, 3, bias=False), nn.BatchNorm2D(64), nn.ReLU(),\n",
    "    nn.MaxPooling2D(2), nn.Dropout(0.25),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(576, 256, bias=False), nn.BatchNorm1D(256), nn.ReLU(),\n",
    "    nn.Linear(256, 128, bias=False), nn.BatchNorm1D(128), nn.ReLU(),\n",
    "    nn.Linear(128, 84, bias=False), nn.BatchNorm1D(84), nn.ReLU(), nn.Dropout(0.25),\n",
    "    nn.Linear(84, 10),\n",
    ")\n",
    "\n",
    "model.to_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = cp.nn.utils.get_module_summary(model, input_shape=(1, 28, 28))\n",
    "print(summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compyute.nn.trainer import Trainer\n",
    "from compyute.nn.trainer.callbacks import History, ProgressBar\n",
    "from compyute.nn.trainer.callbacks.lr_schedulers import AdaptiveLrScheduler\n",
    "\n",
    "optim = nn.optimizers.Adam(model.get_parameters())\n",
    "history = History()\n",
    "scheduler = AdaptiveLrScheduler(optim, target=\"val_loss\", patience=2, lr_downscale_factor=0.2)  # reduces the learning rate when the target metric is not improving\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optim,\n",
    "    loss=\"cross_entropy\",\n",
    "    metric=\"accuracy\",\n",
    "    callbacks=[history, ProgressBar(mode=\"step\"), scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "model.retain_values = True  # keep activations for visualization\n",
    "trainer.train(X_train, y_train, epochs=epochs, batch_size=batch_size, val_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(t1, t2):\n",
    "    trace1 = history[t1]\n",
    "    trace2 = history[t2]\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(cp.arange(start=1, stop=len(trace1) + 1), trace1, linewidth=1)\n",
    "    plt.plot(cp.arange(start=1, stop=len(trace2) + 1), trace2, linewidth=1)\n",
    "\n",
    "plot_history(\"loss\", \"accuracy_score\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = trainer.evaluate_model(X_test, y_test, batch_size)\n",
    "print(f'loss {loss:.4f}')\n",
    "print(f'accuracy {accuracy*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from compyute.nn.utils import batched\n",
    "\n",
    "y_pred = batched(model, batch_size, device, False)(X_test)\n",
    "probs = nn.functional.softmax(y_pred)\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    y_true=y_test.to_numpy(),\n",
    "    y_pred=cp.argmax(probs, dim=-1).to_numpy(),\n",
    "    labels=cp.unique(y_test).to_numpy()\n",
    ")\n",
    "\n",
    "r = cp.arange(10, dtype=cp.int32).to_numpy()\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.xticks(ticks=r, labels=r)\n",
    "plt.yticks(ticks=r, labels=r)\n",
    "for (j, i), label in np.ndenumerate(cm):\n",
    "    plt.text(i, j, str(int(label)), ha=\"center\", va=\"center\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore what the Model has learned\n",
    "Pick a random image from the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(X_test) - 1)\n",
    "image = cp.movedim(X_test[i], from_dim=0, to_dim=-1)  # matplotlib needs the color channel to be the last dim\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(image.data, cmap='gray')\n",
    "plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use it to predict a number and show the probability distribution of the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"correct label: {y_test[i].item()}\")\n",
    "\n",
    "image_tensor = X_test[None, i].to_device(device)\n",
    "\n",
    "# retain values so we can look at intermediates\n",
    "model.retain_values = True\n",
    "logits = model(image_tensor)\n",
    "model.retain_values = False\n",
    "\n",
    "probs = cp.squeeze(cp.nn.functional.softmax(logits)[0])\n",
    "pred = cp.squeeze(cp.argmax(probs, dim=-1)).item()\n",
    "\n",
    "print(f\"predicted label: {pred}\")\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.xticks(ticks=r)\n",
    "plt.bar(r, probs.to_numpy())\n",
    "plt.xlabel(\"class\")\n",
    "plt.ylabel(\"probability\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every layer of the model can be accessed to explore their output. Here we iterate over all the kernels of the convolutional layer to explore what they learned to focus on in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_channels(array, label):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(array.shape[0]):\n",
    "        plt.subplot(10, 8, i + 1)\n",
    "        image = array[i, :, :]\n",
    "        plt.imshow(image, vmin=cp.min(image).item(), vmax=cp.max(image).item(), cmap=\"gray\")\n",
    "        plt.xlabel(f\"channel {str(i + 1)}\")\n",
    "        plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = model.layers[0]\n",
    "\n",
    "out = conv1.y[0].to_cpu()\n",
    "out_min = cp.min(out, dim=0)\n",
    "out_max = cp.max(out, dim=0)\n",
    "out = (out - out_min) / (out_max - out_min)\n",
    "plot_channels(out, \"channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = model.layers[2]\n",
    "\n",
    "out2 = conv2.y[0].to_cpu()\n",
    "out_min2 = cp.min(out2, dim=0)\n",
    "out_max2 = cp.max(out2, dim=0)\n",
    "out2 = (out2 - out_min2) / (out_max2 - out_min2)\n",
    "plot_channels(out2, \"channel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learned filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = cp.sum(conv1.w, dim=1).to_cpu()\n",
    "weights_min1 = cp.min(weights1, dim=0)\n",
    "weights_max1 = cp.max(weights1, dim=0)\n",
    "weights1 = (weights1 - weights_min1) / (weights_max1 - weights_min1)\n",
    "plot_channels(weights1, \"filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2 = cp.sum(conv2.w, dim=1).to_cpu()\n",
    "weights_min2 = cp.min(weights2, dim=0)\n",
    "weights_max2 = cp.max(weights2, dim=0)\n",
    "weights2 = (weights2 - weights_min2) / (weights_max2 - weights_min2)\n",
    "plot_channels(weights2, \"filter\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "deee277ef8cb4a05cf6441d551c854fa5e547ddedbca2c10e6f5685ea62b6c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
