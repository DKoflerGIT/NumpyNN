{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compyute as cp\n",
    "\n",
    "from compyute.functional import zeros, zeros_like\n",
    "from compyute.nn.funcional import sigmoid\n",
    "from compyute.nn import Module\n",
    "from compyute.nn.parameter import Parameter\n",
    "from compyute.random import uniform\n",
    "from compyute.tensor import Tensor\n",
    "from compyute.types import ArrayLike\n",
    "\n",
    "\n",
    "class LSTMCell(Module):\n",
    "    \"\"\"Recurrent cell.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, h_channels: int, use_bias: bool = True, dtype: str = \"float32\") -> None:\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.h_channels = h_channels\n",
    "        self.use_bias = use_bias\n",
    "        self.dtype = dtype\n",
    "\n",
    "        k = in_channels**-0.5\n",
    "\n",
    "        # input gate\n",
    "        w_i = uniform((h_channels, in_channels), -k, k)\n",
    "        self.w_i = Parameter(w_i, dtype=dtype, label=\"w_i\")\n",
    "        u_i = uniform((h_channels, h_channels), -k, k)\n",
    "        self.u_i = Parameter(u_i, dtype=dtype, label=\"u_i\")\n",
    "        if use_bias:\n",
    "            b_i = zeros((h_channels,))\n",
    "            self.b_i = Parameter(b_i, dtype=dtype, label=\"b_i\")\n",
    "\n",
    "        # forget gate\n",
    "        w_f = uniform((h_channels, in_channels), -k, k)\n",
    "        self.w_f = Parameter(w_f, dtype=dtype, label=\"w_f\")\n",
    "        u_f = uniform((h_channels, h_channels), -k, k)\n",
    "        self.u_f = Parameter(u_f, dtype=dtype, label=\"u_f\")\n",
    "        if use_bias:\n",
    "            b_f = zeros((h_channels,))\n",
    "            self.b_f = Parameter(b_f, dtype=dtype, label=\"b_f\")\n",
    "            \n",
    "        # output gate\n",
    "        w_o = uniform((h_channels, in_channels), -k, k)\n",
    "        self.w_o = Parameter(w_o, dtype=dtype, label=\"w_o\")\n",
    "        u_o = uniform((h_channels, h_channels), -k, k)\n",
    "        self.u_o = Parameter(u_o, dtype=dtype, label=\"u_o\")\n",
    "        if use_bias:\n",
    "            b_o = zeros((h_channels,))\n",
    "            self.b_o = Parameter(b_o, dtype=dtype, label=\"b_o\")\n",
    "            \n",
    "        # cell\n",
    "        w_c = uniform((h_channels, in_channels), -k, k)\n",
    "        self.w_c = Parameter(w_c, dtype=dtype, label=\"w_c\")\n",
    "        u_c = uniform((h_channels, h_channels), -k, k)\n",
    "        self.u_c = Parameter(u_c, dtype=dtype, label=\"u_c\")\n",
    "        if use_bias:\n",
    "            b_c = zeros((h_channels,))\n",
    "            self.b_c = Parameter(b_c, dtype=dtype, label=\"b_c\")\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        self.check_dims(x, [3])\n",
    "        x = x.astype(self.dtype)\n",
    "\n",
    "        # input projections\n",
    "        # (B, T, Cin) @ (Cin, Ch) -> (B, T, Ch)\n",
    "        i_h = x @ self.w_i.T\n",
    "        f_h = x @ self.w_f.T\n",
    "        o_h = x @ self.w_i.T\n",
    "        c_h = x @ self.w_i.T\n",
    "\n",
    "        if self.use_bias:\n",
    "            # (B, T, Ch)+ (Ch,) -> (B, T, Ch)\n",
    "            i_h += self.b_i\n",
    "            f_h += self.b_f\n",
    "            o_h += self.b_o\n",
    "            c_h += self.b_c\n",
    "\n",
    "        # iterate over timesteps\n",
    "        i = zeros_like(i_h, dtype=self.dtype, device=self.device)\n",
    "        f = zeros_like(f_h, dtype=self.dtype, device=self.device)\n",
    "        o = zeros_like(o_h, dtype=self.dtype, device=self.device)\n",
    "        c = zeros_like(c_h, dtype=self.dtype, device=self.device)\n",
    "        h = zeros_like(c_h, dtype=self.dtype, device=self.device)\n",
    "\n",
    "        for t in range(x.shape[1]):\n",
    "            i[:, t] = sigmoid(i_h[:, t] + h[:, t - 1] @ self.u_i.T)\n",
    "            f[:, t] = sigmoid(f_h[:, t] + h[:, t - 1] @ self.u_f.T)\n",
    "            o[:, t] = sigmoid(o_h[:, t] + h[:, t - 1] @ self.u_o.T)\n",
    "            c_t_p = (c_h[:, t] + c[:, t - 1] @ self.u_c.T).tanh()\n",
    "            c[:, t] = f[:, t] * c[:, t - 1] + i[:, t] * c_t_p\n",
    "            h[:, t] = o[:, t] * c[:, t].tanh()\n",
    "            \n",
    "        self.set_y(o)\n",
    "        return o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # if self.training:\n",
    "\n",
    "        #     def backward(dy: ArrayLike) -> ArrayLike:\n",
    "        #         dh = dy.astype(self.dtype)\n",
    "        #         self.set_dy(dh)\n",
    "\n",
    "        #         dx_h = zeros_like(x_h, device=self.device).data\n",
    "        #         self.w_i.grad = zeros_like(self.w_h, device=self.device).data\n",
    "        #         self.w_i.grad = zeros_like(self.w_h, device=self.device).data\n",
    "        #         self.w_i.grad = zeros_like(self.w_h, device=self.device).data\n",
    "        #         self.w_i.grad = zeros_like(self.w_h, device=self.device).data\n",
    "\n",
    "        #         for t in range(x.shape[1] - 1, -1, -1):\n",
    "        #             # add hidden state grad of next t, if not last t\n",
    "        #             if t == x_h.shape[1] - 1:\n",
    "        #                 out_grad = dh[:, t]\n",
    "        #             else:\n",
    "        #                 out_grad = dh[:, t] + dx_h[:, t + 1] @ self.w_h.T\n",
    "\n",
    "        #             # activation grads\n",
    "        #             dx_h[:, t] = (1 - h.data[:, t] ** 2) * out_grad\n",
    "\n",
    "        #             # hidden weight grads\n",
    "        #             if t > 0:\n",
    "        #                 self.w_h.grad += h[:, t - 1].T @ dx_h[:, t]\n",
    "\n",
    "        #         # hidden bias grads\n",
    "        #         self.b_h.grad = dx_h.sum((0, 1))\n",
    "\n",
    "        #         # input grads\n",
    "        #         dx = dx_h @ self.w_i.T\n",
    "\n",
    "        #         # input weight grads\n",
    "        #         dw = x.transpose().data @ dx_h\n",
    "        #         self.w_i.grad = dw.sum(axis=0)\n",
    "\n",
    "        #         # input bias grads\n",
    "        #         self.b_i.grad = dx_h.sum((0, 1))\n",
    "\n",
    "        #         return dx\n",
    "\n",
    "        #     self.backward = backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, Ci, Ch = 2, 3, 4, 5\n",
    "\n",
    "X = cp.random.normal((B, T, Ci)).float()\n",
    "lstm = LSTMCell(Ci, Ch)\n",
    "lstm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch_X = torch.tensor(X.to_numpy())\n",
    "torch_lstm = torch.nn.LSTM(Ci, Ch, 1, batch_first=True)\n",
    "torch_lstm(torch_X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_lstm.weight_hh_l0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_lstm.weight_ih_l0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = (x * 2).mean()\n",
    "y.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
