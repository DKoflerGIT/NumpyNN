{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compyute as cp\n",
    "\n",
    "from compyute.functional import zeros_like\n",
    "from compyute.nn.funcional import linear, linear_backward, sigmoid\n",
    "from compyute.nn import Module\n",
    "from compyute.nn.parameter import Parameter\n",
    "from compyute.random import uniform\n",
    "from compyute.tensor import Tensor\n",
    "from compyute.types import DtypeLike\n",
    "\n",
    "from compyute.nn.modules.layers import LSTMCell\n",
    "\n",
    "from tests.test_utils import validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class LSTMCell(Module):\n",
    "#     \"\"\"Long Short-Term Memory cell.\"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         in_channels: int,\n",
    "#         h_channels: int,\n",
    "#         bias: bool = True,\n",
    "#         dtype: DtypeLike = \"float32\",\n",
    "#     ) -> None:\n",
    "#         \"\"\"Long Short-Term Memory cell.\n",
    "#         Input: (B, T, Cin)\n",
    "#             B ... batch, T ... time, Cin ... input channels\n",
    "#         Output: (B, Ch)\n",
    "#             B ... batch, Ch ... hidden channels\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         in_channels : int\n",
    "#             Number of input features.\n",
    "#         h_channels : int\n",
    "#             Number of hidden channels.\n",
    "#         bias : bool, optional\n",
    "#             Whether to use bias values, by default True.\n",
    "#         dtype: DtypeLike, optional\n",
    "#             Datatype of weights and biases, by default \"float32\".\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.in_channels = in_channels\n",
    "#         self.h_channels = h_channels\n",
    "#         self.bias = bias\n",
    "#         self.dtype = dtype\n",
    "\n",
    "#         k = in_channels**-0.5\n",
    "\n",
    "#         # init if\n",
    "#         w_if = uniform((h_channels, in_channels), -k, k)\n",
    "#         self.w_if = Parameter(w_if, dtype=dtype, label=\"w_if\")\n",
    "#         self.b_if = (\n",
    "#             Parameter(uniform((h_channels,), -k, k), dtype=dtype, label=\"b_if\")\n",
    "#             if bias\n",
    "#             else None\n",
    "#         )\n",
    "\n",
    "#         # init hf\n",
    "#         w_hf = uniform((h_channels, h_channels), -k, k)\n",
    "#         self.w_hf = Parameter(w_hf, dtype=dtype, label=\"w_hf\")\n",
    "#         self.b_hf = (\n",
    "#             Parameter(uniform((h_channels,), -k, k), dtype=dtype, label=\"b_hf\")\n",
    "#             if bias\n",
    "#             else None\n",
    "#         )\n",
    "\n",
    "#         # init ii\n",
    "#         w_ii = uniform((h_channels, in_channels), -k, k)\n",
    "#         self.w_ii = Parameter(w_ii, dtype=dtype, label=\"w_ii\")\n",
    "#         self.b_ii = (\n",
    "#             Parameter(uniform((h_channels,), -k, k), dtype=dtype, label=\"b_ii\")\n",
    "#             if bias\n",
    "#             else None\n",
    "#         )\n",
    "\n",
    "#         # init hi\n",
    "#         w_hi = uniform((h_channels, h_channels), -k, k)\n",
    "#         self.w_hi = Parameter(w_hi, dtype=dtype, label=\"w_hi\")\n",
    "#         self.b_hi = (\n",
    "#             Parameter(uniform((h_channels,), -k, k), dtype=dtype, label=\"b_hi\")\n",
    "#             if bias\n",
    "#             else None\n",
    "#         )\n",
    "\n",
    "#         # init ig\n",
    "#         w_ig = uniform((h_channels, in_channels), -k, k)\n",
    "#         self.w_ig = Parameter(w_ig, dtype=dtype, label=\"w_ig\")\n",
    "#         self.b_ig = (\n",
    "#             Parameter(uniform((h_channels,), -k, k), dtype=dtype, label=\"b_ig\")\n",
    "#             if bias\n",
    "#             else None\n",
    "#         )\n",
    "\n",
    "#         # init hg\n",
    "#         w_hg = uniform((h_channels, h_channels), -k, k)\n",
    "#         self.w_hg = Parameter(w_hg, dtype=dtype, label=\"w_hg\")\n",
    "#         self.b_hg = (\n",
    "#             Parameter(uniform((h_channels,), -k, k), dtype=dtype, label=\"b_hg\")\n",
    "#             if bias\n",
    "#             else None\n",
    "#         )\n",
    "\n",
    "#         # init io\n",
    "#         w_io = uniform((h_channels, in_channels), -k, k)\n",
    "#         self.w_io = Parameter(w_io, dtype=dtype, label=\"w_io\")\n",
    "#         self.b_io = (\n",
    "#             Parameter(uniform((h_channels,), -k, k), dtype=dtype, label=\"b_io\")\n",
    "#             if bias\n",
    "#             else None\n",
    "#         )\n",
    "\n",
    "#         # init ho\n",
    "#         w_ho = uniform((h_channels, h_channels), -k, k)\n",
    "#         self.w_ho = Parameter(w_ho, dtype=dtype, label=\"w_ho\")\n",
    "#         self.b_ho = (\n",
    "#             Parameter(uniform((h_channels,), -k, k), dtype=dtype, label=\"b_ho\")\n",
    "#             if bias\n",
    "#             else None\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x: Tensor):\n",
    "#         self.check_dims(x, [3])\n",
    "#         x = x.astype(self.dtype)\n",
    "\n",
    "#         # input projections\n",
    "#         # (B, T, Cin) @ (Cin, Ch) + (Ch,) -> (B, T, Ch)\n",
    "#         f_h = linear(x, self.w_if, self.b_if)\n",
    "#         i_h = linear(x, self.w_ii, self.b_ii)\n",
    "#         g_h = linear(x, self.w_ig, self.b_ig)\n",
    "#         o_h = linear(x, self.w_io, self.b_io)\n",
    "\n",
    "#         # iterate over timesteps\n",
    "#         # (B, T, Ch)\n",
    "#         f = zeros_like(f_h)\n",
    "#         i = zeros_like(i_h)\n",
    "#         g = zeros_like(g_h)\n",
    "#         o = zeros_like(o_h)\n",
    "#         c = zeros_like(f_h)\n",
    "#         h = zeros_like(f_h)\n",
    "\n",
    "#         for t in range(x.shape[1]):\n",
    "#             # (B, 4*Ch) + (B, Ch) @ (Ch, 4*Ch) + (4*Ch,) -> (B, 4*Ch)\n",
    "#             f[:, t] = sigmoid(f_h[:, t] + linear(h[:, t - 1], self.w_hf, self.b_hf))\n",
    "#             i[:, t] = sigmoid(i_h[:, t] + linear(h[:, t - 1], self.w_hi, self.b_hi))\n",
    "#             g[:, t] = (g_h[:, t] + linear(h[:, t - 1], self.w_hg, self.b_hg)).tanh()\n",
    "#             o[:, t] = sigmoid(o_h[:, t] + linear(h[:, t - 1], self.w_ho, self.b_ho))\n",
    "\n",
    "#             c[:, t] = f[:, t] * c[:, t - 1] + i[:, t] * g[:, t]\n",
    "#             h[:, t] = o[:, t] * c[:, t].tanh()\n",
    "\n",
    "#         if self.training:\n",
    "\n",
    "#             # https://pureai.com/articles/2019/11/14/~/media/ECG/pureai/Images/2019/11/lstm_1.asxh\n",
    "\n",
    "#             def backward(dy: Tensor) -> Tensor:\n",
    "#                 dh = dy.astype(self.dtype)\n",
    "#                 self.set_dy(dh)\n",
    "\n",
    "#                 df = zeros_like(f)\n",
    "#                 dc = zeros_like(c)\n",
    "\n",
    "#                 d_sig_f = zeros_like(f)\n",
    "#                 d_sig_i = zeros_like(i)\n",
    "#                 d_tanh_g = zeros_like(g)\n",
    "#                 d_sig_o = zeros_like(o)\n",
    "\n",
    "#                 self.w_hf.grad = zeros_like(self.w_hf)\n",
    "#                 self.w_hi.grad = zeros_like(self.w_hi)\n",
    "#                 self.w_hg.grad = zeros_like(self.w_hg)\n",
    "#                 self.w_ho.grad = zeros_like(self.w_ho)\n",
    "\n",
    "#                 for t in range(x.shape[1] - 1, -1, -1):\n",
    "#                     out_grad = dh[:, t]\n",
    "#                     if t < x.shape[1] - 1:\n",
    "#                         out_grad += d_sig_f[:, t + 1] @ self.w_hf\n",
    "#                         out_grad += d_sig_i[:, t + 1] @ self.w_hi\n",
    "#                         out_grad += d_tanh_g[:, t + 1] @ self.w_hg\n",
    "#                         out_grad += d_sig_o[:, t + 1] @ self.w_ho\n",
    "\n",
    "#                     do_t = c[:, t].tanh() * out_grad\n",
    "\n",
    "#                     dc[:, t] = (1 - c[:, t].tanh() ** 2) * o[:, t] * out_grad\n",
    "#                     if t < x.shape[1] - 1:\n",
    "#                         dc[:, t] += f[:, t + 1] * dc[:, t + 1]\n",
    "\n",
    "#                     df_t = (c[:, t - 1] * dc[:, t]) if t > 0 else 0\n",
    "#                     di_t = g[:, t] * dc[:, t]\n",
    "#                     dg_t = i[:, t] * dc[:, t]\n",
    "\n",
    "#                     d_sig_f[:, t] = f[:, t] * (1 - f[:, t]) * df_t\n",
    "#                     d_sig_i[:, t] = i[:, t] * (1 - i[:, t]) * di_t\n",
    "#                     d_tanh_g[:, t] = (1 - g[:, t] ** 2) * dg_t\n",
    "#                     d_sig_o[:, t] = o[:, t] * (1 - o[:, t]) * do_t\n",
    "\n",
    "#                     if t > 0:\n",
    "#                         self.w_hf.grad += d_sig_f[:, t].T @ h[:, t - 1]\n",
    "#                         self.w_hi.grad += d_sig_i[:, t].T @ h[:, t - 1]\n",
    "#                         self.w_hg.grad += d_tanh_g[:, t].T @ h[:, t - 1]\n",
    "#                         self.w_ho.grad += d_sig_o[:, t].T @ h[:, t - 1]\n",
    "\n",
    "#                 self.b_hf.grad = d_sig_f.sum(axis=(0, 1))\n",
    "#                 self.b_hi.grad = d_sig_i.sum(axis=(0, 1))\n",
    "#                 self.b_hg.grad = d_tanh_g.sum(axis=(0, 1))\n",
    "#                 self.b_ho.grad = d_sig_o.sum(axis=(0, 1))\n",
    "\n",
    "#                 dx = linear_backward(d_sig_f, x, self.w_if, self.b_if)\n",
    "#                 dx += linear_backward(d_sig_i, x, self.w_ii, self.b_ii)\n",
    "#                 dx += linear_backward(d_tanh_g, x, self.w_ig, self.b_ig)\n",
    "#                 dx += linear_backward(d_sig_o, x, self.w_io, self.b_io)\n",
    "\n",
    "#                 return dx\n",
    "\n",
    "#             self.backward = backward\n",
    "\n",
    "#         self.set_y(h)\n",
    "#         return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, L, Hin, Hout = 5, 3, 4, 6\n",
    "\n",
    "X = cp.random.normal((N, L, Hin)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTMCell(Hin, Hout)\n",
    "lstm.training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch_lstm = torch.nn.LSTM(Hin, Hout, batch_first=True)\n",
    "\n",
    "wih_stack = cp.concatenate([lstm.w_ii, lstm.w_if, lstm.w_ig, lstm.w_io], axis=0)\n",
    "torch_lstm.weight_ih_l0 = nn.Parameter(torch.Tensor(wih_stack.to_numpy()), requires_grad=True)\n",
    "\n",
    "bih_stack = cp.concatenate([lstm.b_ii, lstm.b_if, lstm.b_ig, lstm.b_io], axis=0)\n",
    "torch_lstm.bias_ih_l0 = nn.Parameter(torch.Tensor(bih_stack.to_numpy()), requires_grad=True)\n",
    "\n",
    "whh_stack = cp.concatenate([lstm.w_hi, lstm.w_hf, lstm.w_hg, lstm.w_ho], axis=0)\n",
    "torch_lstm.weight_hh_l0 = nn.Parameter(torch.Tensor(whh_stack.to_numpy()), requires_grad=True)\n",
    "\n",
    "bhh_stack = cp.concatenate([lstm.b_hi, lstm.b_hf, lstm.b_hg, lstm.b_ho], axis=0)\n",
    "torch_lstm.bias_hh_l0 = nn.Parameter(torch.Tensor(bhh_stack.to_numpy()), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = lstm(X)\n",
    "torch_X = torch.tensor(X.to_numpy(), requires_grad=True)\n",
    "torch_out = torch_lstm(torch_X)[0]\n",
    "\n",
    "validate(out, torch_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy = cp.random.normal(out.shape)\n",
    "x_grad = lstm.backward(dy)\n",
    "torch_dy = torch.Tensor(dy.to_numpy())\n",
    "torch_out.backward(torch_dy)\n",
    "\n",
    "\n",
    "validate(x_grad, torch_X.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(cp.concatenate([lstm.w_hi.grad, lstm.w_hf.grad, lstm.w_hg.grad, lstm.w_ho.grad], 0), torch_lstm.weight_hh_l0.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(cp.concatenate([lstm.b_hi.grad, lstm.b_hf.grad, lstm.b_hg.grad, lstm.b_ho.grad], 0), torch_lstm.bias_hh_l0.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(cp.concatenate([ lstm.w_ii.grad, lstm.w_if.grad, lstm.w_ig.grad, lstm.w_io.grad], 0), torch_lstm.weight_ih_l0.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(cp.concatenate([lstm.b_ii.grad, lstm.b_if.grad, lstm.b_ig.grad, lstm.b_io.grad], 0), torch_lstm.bias_ih_l0.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
