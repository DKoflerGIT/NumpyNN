{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import walnut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4.1\n",
    "\n",
    "### Convolutional Neural Network: MNIST\n",
    "\n",
    "The goal of this model is to classify images of hand-written digits.\n",
    "\n",
    "### Step 1: Prepare data\n",
    "You will need to download the dataset from https://www.kaggle.com/competitions/digit-recognizer/data and place it into the *data* directory. Only using the official training data for training, validation and testing, since it is just to showcase the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/mnist/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = walnut.pd_to_tensor(data)\n",
    "train, val, test = walnut.preprocessing.split_train_val_test(tensor, ratio_val=0.01, ratio_test=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train[:, 1:], train[:, 0].astype(\"int\")\n",
    "x_val, y_val = val[:, 1:], val[:, 0].astype(\"int\")\n",
    "x_test, y_test = test[:, 1:], test[:, 0].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], 1 , 28, -1))\n",
    "x_val = x_val.reshape((x_val.shape[0], 1, 28, -1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 1, 28, -1))\n",
    "\n",
    "print (f'{x_train.shape=}')\n",
    "print (f'{y_train.shape=}')\n",
    "\n",
    "print (f'{x_val.shape=}')\n",
    "print (f'{y_val.shape=}')\n",
    "\n",
    "print (f'{x_test.shape=}')\n",
    "print (f'{y_test.shape=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_val = x_val.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build the neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import walnut.nn as nn\n",
    "from walnut.nn.layers import *\n",
    "\n",
    "model = nn.Sequential([\n",
    "    Convolution2d(1, 32, kernel_size=(3, 3), use_bias=False), Batchnorm(32), Relu(), # bias not needed when using norm\n",
    "    MaxPooling2d(kernel_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Linear(13*13*32, 200, use_bias=False), Batchnorm(200), Relu(),\n",
    "    Linear(200, 10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=nn.optimizers.Adam(l_r=1e-3),\n",
    "    loss_fn=nn.losses.Crossentropy(),\n",
    "    metric=nn.metrics.Accuracy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from walnut.nn.analysis import model_summary\n",
    "model_summary(model, (1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "train_loss_hist, val_loss_hist = model.train(x_train, y_train, epochs=epochs, batch_size=batch_size, val_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = epochs // 10  # average over the last n values to reduce noise caused by a small batch size\n",
    "\n",
    "traces = {\n",
    "    \"train_loss\" : [np.average(train_loss_hist[i-min(n-1, i):i+1]) for i in range(len(train_loss_hist))],\n",
    "    \"val_loss\" : val_loss_hist\n",
    "}\n",
    "\n",
    "nn.analysis.plot_curve(traces=traces, figsize=(15, 3), title=\"loss history\", x_label=\"epoch\", y_label=\"loss\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'loss {loss:.4f}')\n",
    "print(f'accuracy {accuracy*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(x_test)\n",
    "nn.analysis.plot_confusion_matrix(predictions, y_test, figsize=(5,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Explore the inner workings\n",
    "Pick a random image from the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, x_test.len)\n",
    "image = np.moveaxis(x_test[i].data, 0, -1)\n",
    "plot = plt.imshow(image, cmap='gray')\n",
    "plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use it to predict a number and show the probability distribution of the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = walnut.expand_dims(x_test[i], 0)\n",
    "print(f\"correct label: {y_test[i].item()}\")\n",
    "logits = model(image_tensor)\n",
    "print(f\"predicted label: {logits.argmax(-1).item()}\")\n",
    "nn.analysis.plot_probabilities(logits, figsize=(6, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every layer of the model can be accessed to explore their output. Here we iterate over all the kernels of the convolutional layer to explore what they learned to focus on in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = {f\"{i + 1} {l.__class__.__name__}\" : l.y.data[0].copy() for i, l in enumerate(model.layers) if l.__class__.__name__ == \"Convolution2d\"}\n",
    "nn.analysis.plot_images(channels, figsize=(40, 40), cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "deee277ef8cb4a05cf6441d551c854fa5e547ddedbca2c10e6f5685ea62b6c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
